{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 — Transactions Data Cleaning\n",
    "\n",
    "## 1.0 Business Understanding\n",
    "Dormancy in customer accounts leads to reduced activity, low digital adoption, and lost business opportunities.  \n",
    "To address this, we start by preparing a **clean transactions dataset** covering Dec 2024 – Aug 2025.  \n",
    "\n",
    "This notebook focuses on:\n",
    "- Merging raw monthly transaction reports.  \n",
    "- Excluding invalid statuses (D, J, R).  \n",
    "- Deriving reporting months from transaction dates.  \n",
    "- Classifying transactions into channel groups.  \n",
    "- Saving a clean file for later aggregation.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.0 Data Sources\n",
    "- **Transactions Data (Dec 2024 – Aug 2025)**  \n",
    "  - Location: `data/raw/transactions/`  \n",
    "  - Format: monthly `.csv` / `.xlsx` files.  \n",
    "- **Exclusions**  \n",
    "  - Status codes: D = Declined, J = Reversed, R = Rejected.  \n",
    "- **Confidentiality**  \n",
    "  - Raw files are excluded from GitHub (`.gitignore`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.0 Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Locate Files\n",
    "We check both relative paths (`data/raw/transactions` and `../data/raw/transactions`)  \n",
    "so the notebook works whether run from the project root or the `notebooks/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: C:\\Users\\USER\\Documents\\Personal Projects\\Dormancy\\notebooks\n",
      "Looking in: C:\\Users\\USER\\Documents\\Personal Projects\\Dormancy\\data\\raw\\transactions\n",
      "Files found: 11\n",
      " - Branch Activity - 01.08.25 - 20.08.25.csv\n",
      " - Branch Activity - 21.08.25 - 31.08.25.csv\n",
      " - Branch Activity - 30.06.25.csv\n",
      " - Branch Activity - June 2025.csv\n",
      " - Branch Activity - March 2025.csv\n",
      " - Branch Activity -28.02.25.csv\n",
      " - Branch Activity 30.04.25.csv\n",
      " - Branch Activity 31.01.25.csv\n",
      " - Branch Activity 31.05.25.csv\n",
      " - Branch_Activity - July 2025.csv\n",
      " - Branch Activity - 31.12.24.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Check current working directory\n",
    "print(\"cwd:\", os.getcwd())\n",
    "\n",
    "# Try possible paths\n",
    "p1 = Path(\"data/raw/transactions\")\n",
    "p2 = Path(\"../data/raw/transactions\")\n",
    "\n",
    "if p1.exists():\n",
    "    raw_dir = p1\n",
    "elif p2.exists():\n",
    "    raw_dir = p2\n",
    "else:\n",
    "    raise FileNotFoundError(\"❌ Could not find transactions folder. Check project structure.\")\n",
    "\n",
    "# List files\n",
    "files = list(raw_dir.glob(\"*.csv\")) + list(raw_dir.glob(\"*.xlsx\")) + list(raw_dir.glob(\"*.xls\"))\n",
    "print(\"Looking in:\", raw_dir.resolve())\n",
    "print(\"Files found:\", len(files))\n",
    "for f in files:\n",
    "    print(\" -\", f.name)\n",
    "\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"No transaction files found in {raw_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Load and Merge Monthly Transactions\n",
    "All files are merged into one DataFrame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.0 Load and Merge Monthly Transactions\n",
    "# Function to read CSV or Excel\n",
    "def read_file(f):\n",
    "    if f.suffix.lower() in [\".xlsx\", \".xls\"]:\n",
    "        return pd.read_excel(f)\n",
    "    return pd.read_csv(f)\n",
    "\n",
    "# Merge all transaction files\n",
    "tx = pd.concat([read_file(f) for f in files], ignore_index=True)\n",
    "\n",
    "# Clean column names\n",
    "tx.columns = [c.strip() for c in tx.columns]\n",
    "\n",
    "print(\"Merged shape:\", tx.shape)\n",
    "tx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Clean Data\n",
    "Steps:\n",
    "1. Exclude invalid statuses (D, J, R).  \n",
    "2. Convert `created_date` into datetime.  \n",
    "3. Create `Reporting_Month` = month-end date.  Full-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.0 Clean Data\n",
    "# Steps:\n",
    "# 1. Exclude invalid statuses (D, J, R).\n",
    "# 2. Convert created_date into datetime.\n",
    "# 3. Create Reporting_Month = month-end date.\n",
    "\n",
    "# 1) Exclude invalid statuses\n",
    "tx['status'] = tx['status'].astype(str).str.upper().str.strip()\n",
    "tx = tx[~tx['status'].isin({'D','J','R'})]\n",
    "\n",
    "# 2) Convert created_date\n",
    "tx['created_date'] = pd.to_datetime(tx['created_date'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# 3) Reporting Month\n",
    "tx['Reporting_Month'] = tx['created_date'].dt.to_period('M').dt.to_timestamp('M')\n",
    "\n",
    "tx[['created_date','Reporting_Month']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 Classify Channels\n",
    "Rules:\n",
    "- **Mobile** → tran_type in Mobile Banking (withdrawal, transfer, charges, airtime, utility, paybill, pesalink).  \n",
    "- **Biz2Bank** → RTS PAYBILL DEPOSITS, RTS MPESA DEPOSIT.  \n",
    "- **GABCollect** → GABCollect.  \n",
    "- **Internet** → if created_by = IBKTLR.  \n",
    "- **ATM** → if channels = ATM.  \n",
    "- **Other** → everything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.0 Classify Channels\n",
    "\n",
    "MOBILE_TYPES = {\n",
    "    'MOBILE BANKING MPESA WITHDRAWAL',\n",
    "    'MOBILE BANKING TRANSFER',\n",
    "    'MB CHARGES',\n",
    "    'MOBILE BANKING AIRTIME PURCHASE',\n",
    "    'MB UTILITY PAYMENT',\n",
    "    'MB PAYBILL',\n",
    "    'PESALINK TRANSFER',\n",
    "    'PESALINK DEPOSIT'\n",
    "}\n",
    "BIZ2BANK_TYPES = {'RTS PAYBILL DEPOSITS', 'RTS MPESA DEPOSIT'}\n",
    "\n",
    "def classify_channel(row):\n",
    "    tt = str(row.get('tran_type','')).upper().strip()\n",
    "    created_by = str(row.get('created_by','')).upper().strip()\n",
    "    ch = str(row.get('channels','')).upper().strip()\n",
    "    \n",
    "    if tt in MOBILE_TYPES or tt.startswith(\"MOBILE BANKING\") or \"PESALINK\" in tt:\n",
    "        return \"Mobile\"\n",
    "    if tt in BIZ2BANK_TYPES:\n",
    "        return \"Biz2Bank\"\n",
    "    if tt == \"GABCOLLECT\":\n",
    "        return \"GABCollect\"\n",
    "    if created_by == \"IBKTLR\":\n",
    "        return \"Internet\"\n",
    "    if ch == \"ATM\":\n",
    "        return \"ATM\"\n",
    "    return \"Other\"\n",
    "\n",
    "# Apply classification\n",
    "tx['Channel_Group'] = tx.apply(classify_channel, axis=1)\n",
    "\n",
    "# Flags\n",
    "tx['IsDigital'] = tx['Channel_Group'].isin(['Mobile','Internet','Biz2Bank']).astype(int)\n",
    "tx['IsPhysical'] = tx['Channel_Group'].eq('ATM').astype(int)\n",
    "\n",
    "tx['Channel_Group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.0 Save Clean Transactions\n",
    "The cleaned dataset is saved (ignored by Git)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.0 Save Clean Transactions\n",
    "out_path = Path(\"data/processed/transactions_clean.csv\")\n",
    "tx.to_csv(out_path, index=False)\n",
    "print(\"Clean data saved to:\", out_path.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 — Dormancy_Balances_Cleaning\n",
    "\n",
    "## 1.0 Purpose\n",
    "Balances data provides the monthly end balance per customer.  \n",
    "We will clean this dataset, ensure proper account classification (Current, Savings, FD),  \n",
    "and prepare it for integration with the transactions dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.0 Data Sources\n",
    "- **Balances Data (Dec 2024 – Aug 2025)**  \n",
    "  - Location: `data/raw/balances/`  \n",
    "  - Format: `.csv` or `.xlsx`.  \n",
    "- **GL Mapping**  \n",
    "  - Provided mapping of `gl_name` → Account Type.  \n",
    "- **Confidentiality**  \n",
    "  - Raw files are excluded from GitHub (`.gitignore`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02 — Balances Data Cleaning\n",
    "\n",
    "# 3.0 Import Libraries\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# 4.0 Locate Files\n",
    "print(\"cwd:\", os.getcwd())\n",
    "\n",
    "p1 = Path(\"data/raw/balances\")\n",
    "p2 = Path(\"../data/raw/balances\")\n",
    "\n",
    "if p1.exists():\n",
    "    bal_dir = p1\n",
    "elif p2.exists():\n",
    "    bal_dir = p2\n",
    "else:\n",
    "    raise FileNotFoundError(\"❌ Could not find balances folder. Check project structure.\")\n",
    "\n",
    "bal_files = list(bal_dir.glob(\"*.csv\")) + list(bal_dir.glob(\"*.xlsx\")) + list(bal_dir.glob(\"*.xls\"))\n",
    "print(\"Looking in:\", bal_dir.resolve())\n",
    "print(\"Files found:\", len(bal_files))\n",
    "for f in bal_files:\n",
    "    print(\" -\", f.name)\n",
    "\n",
    "if not bal_files:\n",
    "    raise FileNotFoundError(f\"No balance files found in {bal_dir}\")\n",
    "\n",
    "# 5.0 Load and Merge Monthly Balances\n",
    "def read_file(f):\n",
    "    if f.suffix.lower() in [\".xlsx\", \".xls\"]:\n",
    "        return pd.read_excel(f)\n",
    "    return pd.read_csv(f)\n",
    "\n",
    "balances = pd.concat([read_file(f) for f in bal_files], ignore_index=True)\n",
    "balances.columns = [c.strip() for c in balances.columns]\n",
    "print(\"Merged shape:\", balances.shape)\n",
    "balances.head()\n",
    "\n",
    "# 6.0 Clean Data\n",
    "for col in ['date_opened', 'birth_date', 'date_created']:\n",
    "    if col in balances.columns:\n",
    "        balances[col] = pd.to_datetime(balances[col], errors='coerce', dayfirst=True)\n",
    "\n",
    "if 'Reporting_Month' not in balances.columns:\n",
    "    if 'date_created' in balances.columns:\n",
    "        balances['Reporting_Month'] = balances['date_created'].dt.to_period('M').dt.to_timestamp('M')\n",
    "\n",
    "# 7.0 Map GL Accounts → Account Type\n",
    "gl_mapping = {\n",
    "    'CURRENT ACCOUNT': 'Current',\n",
    "    'SAVINGS ACCOUNT': 'Savings',\n",
    "    'FIXED DEPOSIT': 'FD'\n",
    "}\n",
    "\n",
    "if 'gl_name' in balances.columns:\n",
    "    balances['Account_Type'] = balances['gl_name'].map(\n",
    "        lambda x: gl_mapping.get(str(x).upper(), 'Other')\n",
    "    )\n",
    "\n",
    "print(balances['Account_Type'].value_counts())\n",
    "\n",
    "# 8.0 Save Clean Balances\n",
    "out_path = Path(\"data/processed/balances_clean.csv\")\n",
    "balances.to_csv(out_path, index=False)\n",
    "print(\"Clean balances saved to:\", out_path.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Locate Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cwd:\", os.getcwd())\n",
    "\n",
    "# Try both paths\n",
    "p1 = Path(\"data/raw/balances\")\n",
    "p2 = Path(\"../data/raw/balances\")\n",
    "\n",
    "if p1.exists():\n",
    "    bal_dir = p1\n",
    "elif p2.exists():\n",
    "    bal_dir = p2\n",
    "else:\n",
    "    raise FileNotFoundError(\"❌ Could not find balances folder. Check project structure.\")\n",
    "\n",
    "# Collect files\n",
    "bal_files = list(bal_dir.glob(\"*.csv\")) + list(bal_dir.glob(\"*.xlsx\")) + list(bal_dir.glob(\"*.xls\"))\n",
    "print(\"Looking in:\", bal_dir.resolve())\n",
    "print(\"Files found:\", len(bal_files))\n",
    "for f in bal_files:\n",
    "    print(\" -\", f.name)\n",
    "\n",
    "if not bal_files:\n",
    "    raise FileNotFoundError(f\"No balance files found in {bal_dir}\")/balances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Load and Merge Monthly Balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(f):\n",
    "    if f.suffix.lower() in [\".xlsx\", \".xls\"]:\n",
    "        return pd.read_excel(f)\n",
    "    return pd.read_csv(f)\n",
    "\n",
    "balances = pd.concat([read_file(f) for f in bal_files], ignore_index=True)\n",
    "balances.columns = [c.strip() for c in balances.columns]\n",
    "print(\"Merged shape:\", balances.shape)\n",
    "balances.head()/balances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Clean Data\n",
    "- Convert `date_opened` and other date fields.  \n",
    "- Create `Reporting_Month`.  \n",
    "- Drop duplicates if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates\n",
    "if 'date_opened' in balances.columns:\n",
    "    balances['date_opened'] = pd.to_datetime(balances['date_opened'], errors='coerce', dayfirst=True)\n",
    "\n",
    "if 'birth_date' in balances.columns:\n",
    "    balances['birth_date'] = pd.to_datetime(balances['birth_date'], errors='coerce', dayfirst=True)\n",
    "\n",
    "if 'Reporting_Month' not in balances.columns and 'date_created' in balances.columns:\n",
    "    balances['date_created'] = pd.to_datetime(balances['date_created'], errors='coerce', dayfirst=True)\n",
    "    balances['Reporting_Month'] = balances['date_created'].dt.to_period('M').dt.to_timestamp('M')\n",
    "\n",
    "balances.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 Map GL Accounts → Account Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example mapping dictionary (adjust based on your GL mapping file)\n",
    "gl_mapping = {\n",
    "    'CURRENT ACCOUNT': 'Current',\n",
    "    'SAVINGS ACCOUNT': 'Savings',\n",
    "    'FIXED DEPOSIT': 'FD'\n",
    "}\n",
    "\n",
    "if 'gl_name' in balances.columns:\n",
    "    balances['Account_Type'] = balances['gl_name'].map(lambda x: gl_mapping.get(str(x).upper(), 'Other'))\n",
    "\n",
    "balances['Account_Type'].value_counts()/balances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.0 Save Clean Balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(\"data/processed/balances_clean.csv\")\n",
    "balances.to_csv(out_path, index=False)\n",
    "print(\"/balances Clean balances saved to:\", out_path.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Next Steps\n",
    "Proceed to **Dormancy_Aggregation.ipynb**:\n",
    "- Merge transactions + balances.  \n",
    "- Create customer×month dataset.  \n",
    "- Add dormancy flags.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 03 — Aggregation: Transactions + Balances\n",
    "\n",
    "## 1.0 Purpose\n",
    "Now that we have clean **transactions** and **balances**, we merge them into one dataset.  \n",
    "This creates a **customer × month panel dataset**, which will allow us to:  \n",
    "\n",
    "- Track activity per customer, per month.  \n",
    "- Define **dormancy** (no activity for X months).  \n",
    "- Segment customers by account type (Current, Savings, FD).  \n",
    "\n",
    "---\n",
    "\n",
    "## 2.0 Data Sources\n",
    "- `data/processed/transactions_clean.csv`  \n",
    "- `data/processed/balances_clean.csv`  \n",
    "- Merge on `cif_sub_no` (customer ID) and `Reporting_Month`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.0 Import processed data\n",
    "tx_clean = pd.read_csv(\"data/processed/transactions_clean.csv\", parse_dates=[\"created_date\",\"Reporting_Month\"])\n",
    "bal_clean = pd.read_csv(\"data/processed/balances_clean.csv\", parse_dates=[\"Reporting_Month\"])\n",
    "\n",
    "print(\"Transactions:\", tx_clean.shape)\n",
    "print(\"Balances:\", bal_clean.shape)\n",
    "\n",
    "tx_clean.head(), bal_clean.head()/balances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Aggregate Transactions\n",
    "We compute for each customer × month:\n",
    "- **Total_Transactions**  \n",
    "- **Total_Transaction_Value**  \n",
    "- **Last_Transaction_Date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_tx = (\n",
    "    tx_clean.groupby([\"trs_ac_cif\",\"Reporting_Month\"])\n",
    "    .agg(\n",
    "        Total_Transactions=(\"trs_no\",\"count\"),\n",
    "        Total_Transaction_Value=(\"amount\",\"sum\"),\n",
    "        Last_Transaction_Date=(\"created_date\",\"max\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "agg_tx.head()/balances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Merge with Balances\n",
    "We join balances + transactions by `cif_sub_no` (customer ID) and `Reporting_Month`.  Full-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename to align IDs\n",
    "bal_clean = bal_clean.rename(columns={\"cif_sub_no\":\"trs_ac_cif\"})\n",
    "\n",
    "df = bal_clean.merge(agg_tx, on=[\"trs_ac_cif\",\"Reporting_Month\"], how=\"left\")\n",
    "\n",
    "# Fill NaN for inactive customers (no transactions in that month)\n",
    "df[\"Total_Transactions\"] = df[\"Total_Transactions\"].fillna(0)\n",
    "df[\"Total_Transaction_Value\"] = df[\"Total_Transaction_Value\"].fillna(0)\n",
    "df[\"Last_Transaction_Date\"] = pd.to_datetime(df[\"Last_Transaction_Date\"], errors=\"coerce\")\n",
    "\n",
    "print(\"Merged dataset:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Define Dormancy Flag\n",
    "Business rule:  \n",
    "- **Dormant** = Customer has **0 transactions** in a month on a **Current Account**.  \n",
    "- **Active** = At least 1 transaction.  \n",
    "\n",
    "Later, we’ll refine this into multi-month dormancy windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Dormant_Flag\"] = ((df[\"Total_Transactions\"] == 0) & (df[\"Account_Type\"] == \"Current\")).astype(int)\n",
    "df[\"Active_Flag\"] = (df[\"Dormant_Flag\"] == 0).astype(int)\n",
    "\n",
    "df[[\"trs_ac_cif\",\"Reporting_Month\",\"Account_Type\",\"Total_Transactions\",\"Dormant_Flag\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 Save Aggregated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(\"data/processed/dormancy_dataset.csv\")\n",
    "df.to_csv(out_path, index=False)\n",
    "print(\"Dormancy dataset saved to:\", out_path.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Next Steps\n",
    "Proceed to **04 — Dormancy Analysis**:\n",
    "- Calculate dormancy trends per branch.  \n",
    "- Track digital vs physical activity.  \n",
    "- Identify high-risk customer segments.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 04 — Dormancy Analysis\n",
    "\n",
    "## 1.0 Purpose\n",
    "With the aggregated dataset prepared, we now analyze dormancy patterns:  \n",
    "\n",
    "- Overall dormancy trends across months  \n",
    "- Branch-level dormancy rates  \n",
    "- Digital vs physical activity adoption  \n",
    "- Segmentation by account type (Current, Savings, FD)\n",
    "\n",
    "This will help identify high-risk segments and branches that require intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0 Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Load Dormancy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/processed/dormancy_dataset.csv\", parse_dates=[\"Reporting_Month\",\"Last_Transaction_Date\"])\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Overall Dormancy Trends\n",
    "We measure the share of dormant customers per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_dormancy = (\n",
    "    df.groupby(\"Reporting_Month\")\n",
    "    .agg(\n",
    "        Dormant_Customers=(\"Dormant_Flag\",\"sum\"),\n",
    "        Total_Customers=(\"trs_ac_cif\",\"nunique\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "monthly_dormancy[\"Dormancy_Rate\"] = monthly_dormancy[\"Dormant_Customers\"] / monthly_dormancy[\"Total_Customers\"]\n",
    "\n",
    "monthly_dormancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.lineplot(data=monthly_dormancy, x=\"Reporting_Month\", y=\"Dormancy_Rate\", marker=\"o\")\n",
    "plt.title(\"Dormancy Rate Over Time\")\n",
    "plt.ylabel(\"Dormancy Rate (%)\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Branch-Level Dormancy\n",
    "Which branches have the highest dormancy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_dormancy = (\n",
    "    df.groupby([\"Branch\",\"Reporting_Month\"])\n",
    "    .agg(\n",
    "        Dormant_Customers=(\"Dormant_Flag\",\"sum\"),\n",
    "        Total_Customers=(\"trs_ac_cif\",\"nunique\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "branch_dormancy[\"Dormancy_Rate\"] = branch_dormancy[\"Dormant_Customers\"] / branch_dormancy[\"Total_Customers\"]\n",
    "\n",
    "branch_summary = (\n",
    "    branch_dormancy.groupby(\"Branch\")\n",
    "    .Dormancy_Rate.mean()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "branch_summary.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(\n",
    "    data=branch_summary.reset_index(),\n",
    "    x=\"Dormancy_Rate\",\n",
    "    y=\"Branch\"\n",
    ")\n",
    "plt.title(\"Average Dormancy Rate by Branch\")\n",
    "plt.xlabel(\"Dormancy Rate (%)\")\n",
    "plt.ylabel(\"Branch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Digital vs Physical Activity\n",
    "We compare activity in **digital channels (Mobile, Internet, Biz2Bank)** vs **physical (ATM)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_summary = (\n",
    "    df.groupby(\"Reporting_Month\")\n",
    "    .agg(\n",
    "        Digital_Users=(\"IsDigital\",\"sum\"),\n",
    "        Physical_Users=(\"IsPhysical\",\"sum\"),\n",
    "        Total_Customers=(\"trs_ac_cif\",\"nunique\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "digital_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.lineplot(data=digital_summary, x=\"Reporting_Month\", y=\"Digital_Users\", label=\"Digital\")\n",
    "sns.lineplot(data=digital_summary, x=\"Reporting_Month\", y=\"Physical_Users\", label=\"Physical\")\n",
    "plt.title(\"Digital vs Physical Channel Activity\")\n",
    "plt.ylabel(\"Number of Customers\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 Account Type Segmentation\n",
    "We check dormancy rates across Current, Savings, and FD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acct_dormancy = (\n",
    "    df.groupby([\"Account_Type\",\"Reporting_Month\"])\n",
    "    .agg(\n",
    "        Dormant_Customers=(\"Dormant_Flag\",\"sum\"),\n",
    "        Total_Customers=(\"trs_ac_cif\",\"nunique\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "acct_dormancy[\"Dormancy_Rate\"] = acct_dormancy[\"Dormant_Customers\"] / acct_dormancy[\"Total_Customers\"]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.lineplot(data=acct_dormancy, x=\"Reporting_Month\", y=\"Dormancy_Rate\", hue=\"Account_Type\", marker=\"o\")\n",
    "plt.title(\"Dormancy Rate by Account Type\")\n",
    "plt.ylabel(\"Dormancy Rate (%)\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "- Prepare **findings & recommendations** based on trends.  \n",
    "- Design **branch dashboards** to monitor dormancy.  \n",
    "- Feed results into a final **report for management**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
